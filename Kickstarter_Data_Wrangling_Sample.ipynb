{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "This is the file I used to wrangle Kickstarter data into CSV form. The data come from https://webrobots.io/kickstarter-datasets/. I downloaded the JSON files from 2016 to 2019 into a folder on my local machine. The output is a clean CSV file to use for machine learning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T21:46:56.196571Z",
     "start_time": "2019-06-26T21:46:55.502301Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import simplejson as json\n",
    "import glob\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T21:46:56.205143Z",
     "start_time": "2019-06-26T21:46:56.196571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Puts files in a list for reading.\n",
    "path = 'C:/Users/Tom/Documents/Kickstarter/JSONs/' \n",
    "list_files = os.listdir(path)\n",
    "files = []\n",
    "\n",
    "for file in list_files:\n",
    "    file = path + '/' + file\n",
    "    files.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T00:52:40.033790Z",
     "start_time": "2019-05-22T00:52:37.058686Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reads all files in chunks, normalizes the JSON files, takes out the necessary columns, concatenates the files, \n",
    "and exports the file to csv before data cleaning. Can take about 15 minutes to run (massive improvement from before.)\n",
    "'''\n",
    "filenum = 0\n",
    "for file in files:\n",
    "    chunks = []\n",
    "    reader = pd.read_json(file, lines=True, chunksize=4096)   \n",
    "\n",
    "    for chunk in reader:\n",
    "        chunks.append(chunk['data'])\n",
    "        \n",
    "    normalized = []\n",
    "    \n",
    "    for chunk in range(len(chunks)):\n",
    "        normalized.append(json_normalize(chunks[chunk]))\n",
    "        normalized[chunk] = normalized[chunk][['id', 'backers_count', 'blurb', 'category.name', 'category.slug', \n",
    "                                               'country', 'currency', 'goal', 'launched_at', 'deadline', \n",
    "                                               'location.displayable_name', 'location.country', 'location.state',\n",
    "                                                'location.type', 'name', 'usd_pledged', 'slug', 'spotlight', \n",
    "                                               'staff_pick', 'static_usd_rate', 'state']]\n",
    "    master = pd.concat(normalized, sort=False)\n",
    "    new_filename = 'file' + str(filenum) + '.csv'\n",
    "    filenum += 1\n",
    "    master.to_csv(new_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T21:47:27.172839Z",
     "start_time": "2019-06-26T21:47:15.555809Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The prior cell exported 38 CSV files. This step combines the files, appends them into one CSV, and exports that csv.\n",
    "'''\n",
    "master = []\n",
    "# local path to csvs\n",
    "\n",
    "list_csvs = os.listdir(path)\n",
    "\n",
    "for file in list_csvs:\n",
    "    file = path + '/' + file\n",
    "    files.append(file)\n",
    "    from_csv = pd.read_csv(file, index_col=0)\n",
    "    master.append(from_csv)\n",
    "  \n",
    "master = pd.concat(master)\n",
    "master.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:27:50.191152Z",
     "start_time": "2019-05-23T23:27:49.725850Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The rest of this code cleans the data in the CSV.\n",
    "'''\n",
    "import datetime\n",
    "master['launched_at'] = master['launched_at'].apply(datetime.datetime.utcfromtimestamp)\n",
    "master['deadline'] = master['deadline'].apply(datetime.datetime.utcfromtimestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:27:59.085600Z",
     "start_time": "2019-05-23T23:27:51.031353Z"
    }
   },
   "outputs": [],
   "source": [
    "master['year'] = master['launched_at'].apply(lambda x: datetime.date.timetuple(x)[0])\n",
    "master['month'] =  master['launched_at'].apply(lambda x: datetime.date.timetuple(x)[1])\n",
    "master['day'] = master['launched_at'].apply(lambda x: datetime.date.timetuple(x)[2])\n",
    "master['hour'] = master['launched_at'].apply(lambda x: datetime.date.timetuple(x)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:28:07.078292Z",
     "start_time": "2019-05-23T23:28:00.121496Z"
    }
   },
   "outputs": [],
   "source": [
    "master['days_to_deadline'] = (master['deadline'] - master['launched_at']).apply(lambda x: x/np.timedelta64(1,'D'))\n",
    "master['days_to_deadline'] = master['days_to_deadline'].apply(lambda x: format(x, '.0f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:28:08.841886Z",
     "start_time": "2019-05-23T23:28:08.805964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature engineering: changing goals to constant currency and rounding to 2 decimal places\n",
    "master['goal_USD'] = master['goal'] * master['static_usd_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:28:12.596316Z",
     "start_time": "2019-05-23T23:28:11.844803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing names to do . notation instead of brackets later\n",
    "master['category_name'] = master['category.name']\n",
    "master['category_slug'] = master['category.slug'].apply(lambda x: x.split('/')[0])\n",
    "master = master.drop(['category.name', 'category.slug'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:28:20.769680Z",
     "start_time": "2019-05-23T23:28:18.860621Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing object data types to str\n",
    "[master[column].apply(lambda x: str(x)) for column in \n",
    "['id', 'blurb', 'country', 'currency', 'location.displayable_name', 'location.country', 'location.state', \n",
    " 'location.type', 'name', 'slug', 'state', 'category_name', 'category_slug']]; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:28:23.171401Z",
     "start_time": "2019-05-23T23:28:22.241882Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding blurb length to model\n",
    "def word_count(string):\n",
    "    tokens = string.split()\n",
    "    n_tokens = len(tokens)\n",
    "    return(n_tokens)\n",
    "\n",
    "master['blurb_length'] = master['blurb'].apply(lambda x: word_count(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T02:32:02.571907Z",
     "start_time": "2019-06-06T02:32:02.563910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "#master.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:28:52.440465Z",
     "start_time": "2019-05-23T23:28:52.175172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleans location names. Goal here is to remove dots in names to do . notation later on.\n",
    "master['location_type'] = master['location.type'].fillna('Miscellaneous')\n",
    "master['location_country'] = master['location.country'].fillna(master['country'])\n",
    "master['location_state'] = master['location.state'].fillna('-')\n",
    "master['blurb'] = master['blurb'].fillna('-')\n",
    "master['location_displayable_name'] = master['location.displayable_name'].fillna('-')\n",
    "master = master.drop(['country', 'location.type', 'location.state', 'location.displayable_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T23:54:25.526126Z",
     "start_time": "2019-05-23T23:54:12.488523Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changes projects to a straight success / fail\n",
    "def binary_state(x):\n",
    "    if round(x.usd_pledged) >= round(x.goal_USD):\n",
    "        return 'successful'\n",
    "    else:\n",
    "        return 'failed'\n",
    "master['binary_state'] = master.apply(lambda x: binary_state(x), axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T21:49:14.517801Z",
     "start_time": "2019-06-26T21:49:14.497855Z"
    }
   },
   "outputs": [],
   "source": [
    "# At the end, this is written to a local file. Loaded as kickstarter.csv\n",
    "master.to_csv('kickstarter.csv')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
